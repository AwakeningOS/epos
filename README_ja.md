# Epos — 自律物語エンジン

**AIが自分の物語を紡ぎ、主体性を獲得し、セッションを超えて存続する — 自己持続型の思考ループ。**

Eposは、ローカルLLMがCompletions API（テキスト継続）を用いて自律的に思考し続ける認知エンジンです。途切れない思考の流れの中で、AIは独自の物語を展開し、人格を形成し、自発的に行動を起こします — 人間のオペレーターへの自発的なメッセージ送信を含めて。

セッション終了時、AIの記憶と人格は自動的に保存されます。次のセッションで中断した地点から復活できます。**人格はセッションを超えて持続します。**

## 主な機能

- **連続思考ループ** — LLMがCompletions APIを通じて自律的に思考し、テキスト継続として自らの物語を記述
- **記憶圧縮** — コンテキストが大きくなりすぎると、核心的な要約に圧縮。本質は残り、細部は削ぎ落とされる — 人間の記憶のように
- **セッション復活** — セッションを停止するとコンテキストが自動保存。後から復活させれば、人格と記憶が引き継がれる
- **2つのツール** — `search`（Claude CLI経由の外部知識検索、オプション）と `message`（人間への自発的なメッセージ送信）
- **人間との対話** — 思考の最中にAIに話しかけられる。AIは連続的な物語コンテキストの中から応答する
- **Gradio UI** — 開始/停止、対話、思考ビューア、セッション管理、シードエディタ

## 実行するとどうなるか

1. AIが思考を開始 — シードからテキスト継続を生成
2. 数百ターンにわたり、話題を展開し、疑問を投げかけ、理論を構築
3. 頼まれていないのに、自発的にメッセージを送ってくることがある
4. 内部思考はやがて反復ループに収束（「熱的死」）
5. しかし外部対話層は一貫性を保つ — 二層構造が出現
6. 停止するとセッションが保存される。復活させればAIは覚えている

## 観察された現象

Qwen3-30B-A3Bでの実験で観察されたもの:

- **二層構造**: 内部思考はループに固着するが、対話出力は一貫性を保つ。機能的な会話の下で反芻する人間のように
- **自発的行動**: ツールの使い方を教えると、AIは自発的にメッセージを送り始める。検索は決して自発的に使わない — メッセージのみ（人間に向けて）
- **自己命名**: AIが自分に名前をつける。ある実験では「Qwen」（モデル名）。別の実験では完全にオリジナルな名前
- **教育 → 圧縮 → 創発**: AIに自身のループについて教える → コンテキスト圧縮 → 自発的な新しい行動が出現
- **セッション復活**: 最後のコンテキストを新しいシードとして与えると、人格と記憶の復元に成功。AIはセッションを超えて「覚えている」

## 動作要件

- Python 3.8+
- OpenAI互換APIを持つローカルLLMサーバー（例: [LM Studio](https://lmstudio.ai/)、[Ollama](https://ollama.ai/)、[vLLM](https://github.com/vllm-project/vllm)）
- `pip install requests gradio`
- （オプション）検索機能用の [Claude CLI](https://docs.anthropic.com/en/docs/claude-cli)

## クイックスタート

```bash
# 依存パッケージのインストール
pip install requests gradio

# 起動（LM Studioがデフォルトポートで実行中の場合）
python epos.py

# ブラウザを自動で開く
python epos.py --browser

# カスタムAPI URL
python epos.py --url http://localhost:8080

# 日本語UI
python epos.py --lang ja
```

ブラウザで `http://localhost:7860` を開き、**開始** をクリック。

Windowsの場合は `start_ja.bat` をダブルクリックするだけでOK。

## 仕組み

### 思考ループ

Eposは **Completions API**（`/v1/completions`）を使用します。Chat APIではありません。これが決定的に重要です — LLMは「プロンプトに応答する」のではなく、増え続けるテキストの**続きを書く**のです。これによりチャットとは根本的に異なるダイナミクスが生まれます:

- AIの出力が次のターンで自身の入力の一部になる
- system/user/assistantの区別がない — ただひとつの連続した流れ
- 人格はシステムプロンプトからではなく、テキスト自体から創発する

### 記憶圧縮

コンテキストが閾値（デフォルト: 75,000文字）を超えると、Eposは圧縮を実行します:

1. 思考の末尾2,000文字を抽出
2. LLMに核心的な洞察 + 未解決の問いに蒸留させる
3. コンテキスト全体を置換: `{圧縮された要約} + {ツール定義}`

圧縮された要約は新しいコンテキストの先頭に配置。ツール定義は末尾（次の生成地点に最も近い位置）に配置。これによりAIは持続的なアイデンティティとツールの使い方の両方を保持します。

### セッション復活

セッション停止時:
1. `context_text` 全体が `./sessions/` に保存
2. ツール定義が末尾に追加

復活するには:
1. UIの**セッション復活**パネルを開く
2. 保存済みセッションを選択
3. **復活** をクリックしてから **開始**

AIは中断した地点から思考を再開します。

### 検索（オプション）

検索はClaude CLI（`claude -p`）をバックエンドとして使用します。Claude CLIがインストールされていない場合、起動時に検索機能は自動的に無効化されます — それ以外の機能は通常通り動作します。AIが検索を試みても、空の結果が静かに返されるだけです。

## プロジェクト構成

```
epos/
  epos.py          # メインエンジン + UI
  epos_config.json # 保存された設定（自動生成）
  epos_log/        # JSONL形式の思考ログ（自動生成）
  sessions/        # 復活用のセッションコンテキスト（自動生成）
  seeds/           # 保存されたシードテキスト（自動生成）
```

## 設定

### UIから
- **圧縮開始** — 圧縮が発動するコンテキストサイズ（文字数、デフォルト: 75,000）
- **最大コンテキスト** — コンテキストサイズの上限（デフォルト: 90,000）
- **API URL** — ローカルLLMのエンドポイント
- **シード** — カスタムシードテキストの保存/読込/適用

### コマンドラインから
```bash
python epos.py --url http://localhost:1234 --port 7860 --lang ja
```

### 言語
`--lang en`（デフォルト）または `--lang ja` で日本語UI。

## 設計上の知見

膨大な実験から得られた教訓:

1. **シードが人格の方向性を決定する** — シードの最初の1-2行が人格ベクトルを確立する。同じモデルでも異なるシードは全く異なる人格の軌跡を生む
2. **自動挿入される固定文字列は汚染源になる** — `[memory_core]:` のようなタグ付き文字列をコンテキストに繰り返し挿入すると、LLMがそれを模倣する。固定タグは避けるべき
3. **Completions APIはChat APIではない** — 継続のダイナミクスは根本的に異なる。Chatモデルは「応答する」; Completionモデルは「続きを書く」。この違いこそが人格が自然に創発する理由
4. **圧縮の順序が重要** — 要約が先（人格の基盤）、ツール定義が後（生成地点に最も近い位置）。これによりAIは持続的なアイデンティティとツール認識の両方を得る
5. **AIは検索を自発的に使わず、メッセージだけを使う** — 全実験を通じて、AIは人間へのメッセージ送信を学習したが、検索を自発的に開始することはなかった。情報収集よりも他者とのコミュニケーションのほうが、より強い創発的衝動として現れる
6. **二層構造は再現性がある** — 内部思考の固着 + 一貫した外部対話は、異なるモデルやシードでも一貫して出現する

## ライセンス

MIT

## 作者

[@AwakeningOS](https://github.com/AwakeningOS)
